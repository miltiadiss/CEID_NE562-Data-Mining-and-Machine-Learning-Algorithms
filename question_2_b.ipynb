{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2um5JuL1oi5Yyy95hwY0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miltiadiss/Data-Mining/blob/main/question_2_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def create_lags(df, lag):\n",
        "    # Επιλογή των στηλών που θα καθυστερήσουν (αφαιρούμε τις άχρηστες στήλες 'timestamp' και 'label')\n",
        "    cols_to_shift = [col for col in df.columns if (col != 'timestamp' and col != 'label')]\n",
        "    # Δημιουργία ενός λεξικού που περιέχει τις καθυστερημένες στήλες\n",
        "    lagged_data = {f'{col}_lag_{i}': df[col].shift(i) for col in cols_to_shift for i in range(1, lag + 1)}\n",
        "    # Δημιουργία ενός νέου DataFrame από το λεξικό με τα καθυστερημένα δεδομένα\n",
        "    lagged_df = pd.DataFrame(lagged_data)\n",
        "    # Συνένωση του αρχικού DataFrame με το DataFrame που περιέχει τα καθυστερημένα δεδομένα\n",
        "    df = pd.concat([df, lagged_df], axis=1)\n",
        "    # Αντικατάσταση των τιμών NaN που δημιουργήθηκαν από τις καθυστερήσεις με 0\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "# Μονοπάτι για τον φάκελο που περιέχει τα αρχεία CSV\n",
        "path = '/content/drive/MyDrive/harth'"
      ],
      "metadata": {
        "id": "uWXrPDzIRKLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 Bayesian Network**"
      ],
      "metadata": {
        "id": "tImURVUuNT_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgkhaSdFNPmz",
        "outputId": "0e4cb8e2-7c36-4c5b-c6f2-b44a6bf9401c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Product space too large to allocate arrays!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-41d50bfb26dc>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mExpectationMaximization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Δημιουργία των CPD χρησιμοποιώντας MLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pgmpy/models/BayesianNetwork.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, estimator, state_names, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mstate_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         )\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mcpds_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cpds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcpds_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pgmpy/estimators/EM.py\u001b[0m in \u001b[0;36mget_parameters\u001b[0;34m(self, latent_card, max_iter, atol, n_jobs, batch_size, seed, init_cpds, show_progress)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfixed_cpd_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mfixed_cpds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_cpd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Step 3.2: Randomly initialize the CPDs involving latent variables if init_cpds is not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pgmpy/estimators/MLE.py\u001b[0m in \u001b[0;36mestimate_cpd\u001b[0;34m(self, node, weighted)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mstate_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# if a column contains only `0`s (no states observed for some configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pgmpy/estimators/base.py\u001b[0m in \u001b[0;36mstate_counts\u001b[0;34m(self, variable, weighted, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         return super(ParameterEstimator, self).state_counts(\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pgmpy/estimators/base.py\u001b[0m in \u001b[0;36mstate_counts\u001b[0;34m(self, variable, parents, weighted, reindex)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;31m#                  did not occur in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mrow_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mcolumn_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 state_counts = state_count_data.reindex(\n\u001b[1;32m    167\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mfrom_product\u001b[0;34m(cls, iterables, sortorder, names)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# codes are all ndarrays, so cartesian_product is lossless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcartesian_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msortorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msortorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/util.py\u001b[0m in \u001b[0;36mcartesian_product\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumprodX\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Product space too large to allocate arrays!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumprodX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Product space too large to allocate arrays!"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import ExpectationMaximization\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "# Λίστες για την αποθήκευση των μετρικών από κάθε αρχείο\n",
        "bn_accuracies = []  # Ακρίβεια για κάθε αρχείο\n",
        "bn_precisions = []  # Precision για κάθε αρχείο\n",
        "bn_recalls = []     # Recall για κάθε αρχείο\n",
        "bn_f1_scores = []   # F1-score για κάθε αρχείο\n",
        "\n",
        "def discretize_columns(df, bins):\n",
        "    cols_to_discretize = [col for col in df.columns if col not in ['timestamp', 'label']]\n",
        "    discretizer = KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='uniform')\n",
        "    df[cols_to_discretize] = discretizer.fit_transform(df[cols_to_discretize])\n",
        "    return df\n",
        "\n",
        "# Επανάληψη μέσω των αρχείων στο φάκελο\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        # Φόρτωση του CSV αρχείου\n",
        "        df = pd.read_csv(os.path.join(path, filename))\n",
        "\n",
        "        # Δημιουργία των καθυστερήσεων\n",
        "        df = create_lags(df, 50)\n",
        "\n",
        "        # Διακριτοποίηση των χαρακτηριστικών\n",
        "        df = discretize_columns(df, bins=3)\n",
        "\n",
        "        # Διαίρεση σε train και test σύνολα\n",
        "        train_size = int(0.7 * len(df))\n",
        "        train_df = df.iloc[:train_size]\n",
        "        test_df = df.iloc[train_size:]\n",
        "\n",
        "        X_train = train_df.drop(['timestamp'], axis=1)\n",
        "        #y_train = train_df['label']\n",
        "        X_test = test_df.drop(['timestamp','label'], axis=1)\n",
        "        y_test = test_df['label']\n",
        "\n",
        "        # Εκπαίδευση ενός Gaussian Bayesian Network\n",
        "        model = BayesianNetwork()\n",
        "\n",
        "        # Προσθήκη ακμών (συνδέσεων) στο γράφο με βάση τις μεταβλητές στο σύνολο δεδομένων\n",
        "        features = [col for col in df.columns if col not in ['timestamp', 'label']]\n",
        "        edges = [(feature, 'label') for feature in features]  # Ορίζουμε μια ακμή από κάθε χαρακτηριστικό προς τη μεταβλητή label\n",
        "        model.add_edges_from(edges)\n",
        "\n",
        "        model.fit(X_train, estimator=ExpectationMaximization)\n",
        "\n",
        "        # Δημιουργία των CPD χρησιμοποιώντας MLE\n",
        "        cpds = {}\n",
        "        for feature in features:\n",
        "            cpd_values = model.get_cpds(feature).values.reshape(-1, 3)\n",
        "            cpds[feature] = TabularCPD(variable=feature, variable_card=3,\n",
        "                                       evidence=['label'], evidence_card=[11],\n",
        "                                       values=cpd_values)\n",
        "\n",
        "        # Προσθήκη των CPD στο μοντέλο\n",
        "        for feature in features:\n",
        "            model.add_cpds(cpds[feature])\n",
        "\n",
        "        # Απόδοση του μοντέλου\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Υπολογίζουμε τις μετρικες και τις προσθέτουμε στις λίστες\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        bn_accuracies.append(accuracy)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        bn_precisions.append(precision)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        bn_recalls.append(recall)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        bn_f1_scores.append(f1)\n",
        "\n",
        "        # Εκτύπωση των μετρικών για κάθε συμμετέχοντα\n",
        "        base_name = os.path.splitext(filename)[0]  # Χωρίς κατάληξη\n",
        "        print(f\"Metrics for Participant {base_name}:\")\n",
        "        print(f\"  Accuracy: {accuracy}\")\n",
        "        print(f\"  Precision: {precision}\")\n",
        "        print(f\"  Recall: {recall}\")\n",
        "        print(f\"  F1-Score: {f1}\")\n",
        "\n",
        "        # Υπολογισμός και εμφάνιση του confusion matrix\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_labels, yticklabels=unique_labels)\n",
        "        plt.title(f'Confusion Matrix for Participant {base_name}')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.show()\n",
        "\n",
        "# Υπολογισμός της μέσης τιμής για κάθε μετρική από όλους τους συμμετέχοντες\n",
        "bn_mean_accuracy = np.mean(bn_accuracies)\n",
        "bn_mean_precision = np.mean(bn_precisions)\n",
        "bn_mean_recall = np.mean(bn_recalls)\n",
        "bn_mean_f1 = np.mean(bn_f1_scores)\n",
        "\n",
        "print(\"Mean Metrics of All Participants:\")\n",
        "print(f\"  Mean Accuracy: {bn_mean_accuracy}\")\n",
        "print(f\"  Mean Precision: {bn_mean_precision}\")\n",
        "print(f\"  Mean Recall: {bn_mean_recall}\")\n",
        "print(f\"  Mean F1-Score: {bn_mean_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator, HillClimbSearch, BicScore\n",
        "from pgmpy.inference import VariableElimination\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "def discretize_columns(df, bins):\n",
        "    cols_to_discretize = [col for col in df.columns if col not in ['timestamp', 'label']]\n",
        "    discretizer = KBinsDiscretizer(n_bins=bins, encode='ordinal', strategy='uniform')\n",
        "    df[cols_to_discretize] = discretizer.fit_transform(df[cols_to_discretize])\n",
        "    return df\n",
        "\n",
        "# Λίστες για την αποθήκευση των μετρικών από κάθε αρχείο\n",
        "bn_accuracies = []  # Ακρίβεια για κάθε αρχείο\n",
        "bn_precisions = []  # Precision για κάθε αρχείο\n",
        "bn_recalls = []     # Recall για κάθε αρχείο\n",
        "bn_f1_scores = []   # F1-score για κάθε αρχείο\n",
        "\n",
        "# Επανάληψη μέσω των αρχείων στο φάκελο\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        # Φόρτωση του CSV αρχείου\n",
        "        df = pd.read_csv(os.path.join(path, filename))\n",
        "\n",
        "        # Δημιουργία των καθυστερήσεων\n",
        "        df = create_lags(df, 10)\n",
        "\n",
        "        # Διακριτοποίηση των χαρακτηριστικών\n",
        "        df = discretize_columns(df, bins=3)\n",
        "\n",
        "        # Διαίρεση σε train και test σύνολα\n",
        "        train_size = int(0.8 * len(df))\n",
        "        train_df = df.iloc[:train_size]\n",
        "        test_df = df.iloc[train_size:]\n",
        "\n",
        "        X_train = train_df.drop(['timestamp', 'label'], axis=1)\n",
        "        y_train = train_df['label']\n",
        "        X_test = test_df.drop(['timestamp', 'label'], axis=1)\n",
        "        y_test = test_df['label']\n",
        "\n",
        "        # Συνδυασμός X_train και y_train για δημιουργία DataFrame για εκπαίδευση του Bayesian Network\n",
        "        train_df = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "        # Δημιουργία δομής του Bayesian Network με χρήση του αλγορίθμου HillClimbSearch και της μετρικής BIC\n",
        "        hc = HillClimbSearch(train_df)\n",
        "        best_model = hc.estimate(scoring_method=BicScore(train_df))\n",
        "\n",
        "        # Δημιουργία του μοντέλου Bayesian Network με βάση τις βέλτιστες συνδέσεις που προέκυψαν από τον αλγόριθμο HillClimbSearch\n",
        "        model = BayesianNetwork(best_model.edges())\n",
        "        model.fit(train_df, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "        # Απόδοση του μοντέλου\n",
        "        infer = VariableElimination(model)\n",
        "        y_pred = []\n",
        "\n",
        "        for _, row in X_test.iterrows():\n",
        "            evidence = row.to_dict()\n",
        "            query_result = infer.map_query(variables=['label'], evidence=evidence)\n",
        "            y_pred.append(query_result['label'])\n",
        "\n",
        "        # Υπολογίζουμε τις μετρικες και τις προσθέτουμε στις λίστες\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        bn_accuracies.append(accuracy)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        bn_precisions.append(precision)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        bn_recalls.append(recall)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        bn_f1_scores.append(f1)\n",
        "\n",
        "        # Εκτύπωση των μετρικών για κάθε συμμετέχοντα\n",
        "        base_name = os.path.splitext(filename)[0]  # Χωρίς κατάληξη\n",
        "        print(f\"Metrics for Participant {base_name}:\")\n",
        "        print(f\"  Accuracy: {accuracy}\")\n",
        "        print(f\"  Precision: {precision}\")\n",
        "        print(f\"  Recall: {recall}\")\n",
        "        print(f\"  F1-Score: {f1}\")\n",
        "\n",
        "        # Υπολογισμός και εμφάνιση του confusion matrix\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_labels, yticklabels=unique_labels)\n",
        "        plt.title(f'Confusion Matrix for Participant {base_name}')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.show()\n",
        "\n",
        "# Υπολογισμός της μέσης τιμής για κάθε μετρική από όλους τους συμμετέχοντες\n",
        "bn_mean_accuracy = np.mean(bn_accuracies)\n",
        "bn_mean_precision = np.mean(bn_precisions)\n",
        "bn_mean_recall = np.mean(bn_recalls)\n",
        "bn_mean_f1 = np.mean(bn_f1_scores)\n",
        "\n",
        "print(\"Mean Metrics of All Participants:\")\n",
        "print(f\"  Mean Accuracy: {bn_mean_accuracy}\")\n",
        "print(f\"  Mean Precision: {bn_mean_precision}\")\n",
        "print(f\"  Mean Recall: {bn_mean_recall}\")\n",
        "print(f\"  Mean F1-Score: {bn_mean_f1}\")"
      ],
      "metadata": {
        "id": "avA2MDdcBwo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 Σύγκριση Ταξινομητών**"
      ],
      "metadata": {
        "id": "r2WCU5YnNaNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Λίστα με τα ονόματα των συμμετεχόντων\n",
        "participants = [os.path.splitext(filename)[0] for filename in os.listdir(path) if filename.endswith(\".csv\")]\n",
        "\n",
        "# Δημιουργία DataFrame για να συγκρίνουμε τις ακριβείες των δύο μοντέλων\n",
        "accuracy_df = pd.DataFrame({\n",
        "    'Participant': participants,\n",
        "    'Random Forest Accuracy': rf_accuracies,\n",
        "    'Neural Network Accuracy': ann_accuracies,\n",
        "    'Bayesian Network Accuracy': bn_accuracies\n",
        "})\n",
        "\n",
        "# Σχεδιασμός του γραφήματος\n",
        "plt.figure(figsize=(15, 8))\n",
        "bar_width = 0.25\n",
        "index = np.arange(len(participants))\n",
        "\n",
        "# Μπάρες για τις ακρίβειες του Random Forest\n",
        "plt.bar(index, accuracy_df['Random Forest Accuracy'][accuracy_df['Participant'] != 'S015'], bar_width, label='Random Forest')\n",
        "\n",
        "# Μπάρες για τις ακρίβειες του ANN\n",
        "plt.bar(index + bar_width, accuracy_df['Neural Network Accuracy'][accuracy_df['Participant'] != 'S015'], bar_width, label='ANN')\n",
        "\n",
        "# Μπάρες για τις ακρίβειες του Bayesian Network\n",
        "plt.bar(index + 2 * bar_width, accuracy_df['Bayesian Network Accuracy'][accuracy_df['Participant'] != 'S015'], bar_width, label='Bayesian Network')\n",
        "\n",
        "# Προσθήκη ετικετών και τίτλων\n",
        "plt.xlabel('Participant')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Classifier Accuracy for Each Participant')\n",
        "plt.xticks(index[accuracy_df['Participant'] != 'S015'] + 1.5 * bar_width, accuracy_df['Participant'][accuracy_df['Participant'] != 'S015'], rotation=45)\n",
        "plt.legend()\n",
        "\n",
        "# Εμφάνιση του γραφήματος\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zFQ-euzoNan4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}